{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import math as m\n",
    "import sys\n",
    "from scipy.special import gamma as tgamma\n",
    "import os\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGGDfit(structdis):\n",
    "    # variables to count positive pixels / negative pixels and their squared sum\n",
    "    poscount = 0\n",
    "    negcount = 0\n",
    "    possqsum = 0\n",
    "    negsqsum = 0\n",
    "    abssum   = 0\n",
    "\n",
    "    poscount = len(structdis[structdis > 0]) # number of positive pixels\n",
    "    negcount = len(structdis[structdis < 0]) # number of negative pixels\n",
    "    \n",
    "    # calculate squared sum of positive pixels and negative pixels\n",
    "    possqsum = np.sum(np.power(structdis[structdis > 0], 2))\n",
    "    negsqsum = np.sum(np.power(structdis[structdis < 0], 2))\n",
    "    \n",
    "    # absolute squared sum\n",
    "    abssum = np.sum(structdis[structdis > 0]) + np.sum(-1 * structdis[structdis < 0])\n",
    "\n",
    "    # calculate left sigma variance and right sigma variance\n",
    "    lsigma_best = np.sqrt((negsqsum/negcount))\n",
    "    rsigma_best = np.sqrt((possqsum/poscount))\n",
    "\n",
    "    gammahat = lsigma_best/rsigma_best\n",
    "    \n",
    "    # total number of pixels - totalcount\n",
    "    totalcount = structdis.shape[1] * structdis.shape[0]\n",
    "\n",
    "    rhat = m.pow(abssum/totalcount, 2)/((negsqsum + possqsum)/totalcount)\n",
    "    rhatnorm = rhat * (m.pow(gammahat, 3) + 1) * (gammahat + 1)/(m.pow(m.pow(gammahat, 2) + 1, 2))\n",
    "    \n",
    "    prevgamma = 0\n",
    "    prevdiff  = 1e10\n",
    "    sampling  = 0.001\n",
    "    gam = 0.2\n",
    "\n",
    "    # vectorized function call for best fitting parameters\n",
    "    vectfunc = np.vectorize(func, otypes = [np.float], cache = False)\n",
    "    \n",
    "    # calculate best fit params\n",
    "    gamma_best = vectfunc(gam, prevgamma, prevdiff, sampling, rhatnorm)\n",
    "\n",
    "    return [lsigma_best, rsigma_best, gamma_best] \n",
    "\n",
    "def func(gam, prevgamma, prevdiff, sampling, rhatnorm):\n",
    "    while(gam < 10):\n",
    "        r_gam = tgamma(2/gam) * tgamma(2/gam) / (tgamma(1/gam) * tgamma(3/gam))\n",
    "        diff = abs(r_gam - rhatnorm)\n",
    "        if(diff > prevdiff): break\n",
    "        prevdiff = diff\n",
    "        prevgamma = gam\n",
    "        gam += sampling\n",
    "    gamma_best = prevgamma\n",
    "    return gamma_best\n",
    "\n",
    "#function to create features\n",
    "def compute_features(img):\n",
    "    scalenum = 2\n",
    "    feat = []\n",
    "    # make a copy of the image \n",
    "    im_original = img.copy()\n",
    "\n",
    "    # scale the images twice \n",
    "    for itr_scale in range(scalenum):\n",
    "        im = im_original.copy()\n",
    "        # normalize the image\n",
    "        im = im / 255.0\n",
    "\n",
    "        # calculating MSCN coefficients\n",
    "        mu = cv2.GaussianBlur(im, (7, 7), 1.166)\n",
    "        mu_sq = mu * mu\n",
    "        sigma = cv2.GaussianBlur(im*im, (7, 7), 1.166)\n",
    "        sigma = (sigma - mu_sq)**0.5\n",
    "        \n",
    "        # structdis is the MSCN image\n",
    "        structdis = im - mu\n",
    "        structdis /= (sigma + 1.0/255)\n",
    "    \n",
    "        # calculate best fitted parameters from MSCN image\n",
    "        best_fit_params = AGGDfit(structdis)\n",
    "        # unwrap the best fit parameters \n",
    "        lsigma_best = best_fit_params[0]\n",
    "        rsigma_best = best_fit_params[1]\n",
    "        gamma_best  = best_fit_params[2]\n",
    "        \n",
    "        # append the best fit parameters for MSCN image\n",
    "        feat.append(gamma_best)\n",
    "        feat.append((lsigma_best*lsigma_best + rsigma_best*rsigma_best)/2)\n",
    "\n",
    "        # shifting indices for creating pair-wise products\n",
    "        shifts = [[0,1], [1,0], [1,1], [-1,1]] # H V D1 D2\n",
    "\n",
    "        for itr_shift in range(1, len(shifts) + 1):\n",
    "            OrigArr = structdis\n",
    "            reqshift = shifts[itr_shift-1] # shifting index\n",
    "\n",
    "            # create transformation matrix for warpAffine function\n",
    "            M = np.float32([[1, 0, reqshift[1]], [0, 1, reqshift[0]]])\n",
    "            ShiftArr = cv2.warpAffine(OrigArr, M, (structdis.shape[1], structdis.shape[0]))\n",
    "            \n",
    "            Shifted_new_structdis = ShiftArr\n",
    "            Shifted_new_structdis = Shifted_new_structdis * structdis\n",
    "            # shifted_new_structdis is the pairwise product \n",
    "            # best fit the pairwise product \n",
    "            best_fit_params = AGGDfit(Shifted_new_structdis)\n",
    "            lsigma_best = best_fit_params[0]\n",
    "            rsigma_best = best_fit_params[1]\n",
    "            gamma_best  = best_fit_params[2]\n",
    "\n",
    "            constant = m.pow(tgamma(1/gamma_best), 0.5)/m.pow(tgamma(3/gamma_best), 0.5)\n",
    "            meanparam = (rsigma_best - lsigma_best) * (tgamma(2/gamma_best)/tgamma(1/gamma_best)) * constant\n",
    "\n",
    "            # append the best fit calculated parameters            \n",
    "            feat.append(gamma_best) # gamma best\n",
    "            feat.append(meanparam) # mean shape\n",
    "            feat.append(m.pow(lsigma_best, 2)) # left variance square\n",
    "            feat.append(m.pow(rsigma_best, 2)) # right variance square\n",
    "        \n",
    "        # resize the image on next iteration\n",
    "        im_original = cv2.resize(im_original, (0,0), fx=0.5, fy=0.5, interpolation=cv2.INTER_CUBIC)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to create features and scale them\n",
    "# takes input of the image path\n",
    "def test_measure_BRISQUE(imgPath):\n",
    "    # read image from given path\n",
    "    dis = cv2.imread(imgPath, 1)\n",
    "    if(dis is None):\n",
    "        print(\"Wrong image path given\")\n",
    "        print(\"Exiting...\")\n",
    "        sys.exit(0)\n",
    "    # convert to gray scale\n",
    "    dis = cv2.cvtColor(dis, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # compute feature vectors of the image\n",
    "    features = compute_features(dis)\n",
    "    # rescale the brisqueFeatures vector from -1 to 1\n",
    "    x=[0]\n",
    "    \n",
    "    # pre loaded lists from Module to rescale brisquefeatures vector to [-1, 1]\n",
    "    min_= [0.336999 ,0.019667 ,0.230000 ,-0.125959 ,0.000167 ,0.000616 ,0.231000 ,-0.125873 ,0.000165 ,0.000600 ,0.241000 ,-0.128814 ,0.000179 ,0.000386 ,0.243000 ,-0.133080 ,0.000182 ,0.000421 ,0.436998 ,0.016929 ,0.247000 ,-0.200231 ,0.000104 ,0.000834 ,0.257000 ,-0.200017 ,0.000112 ,0.000876 ,0.257000 ,-0.155072 ,0.000112 ,0.000356 ,0.258000 ,-0.154374 ,0.000117 ,0.000351]\n",
    "    \n",
    "    max_= [9.999411, 0.807472, 1.644021, 0.202917, 0.712384, 0.468672, 1.644021, 0.169548, 0.713132, 0.467896, 1.553016, 0.101368, 0.687324, 0.533087, 1.554016, 0.101000, 0.689177, 0.533133, 3.639918, 0.800955, 1.096995, 0.175286, 0.755547, 0.399270, 1.095995, 0.155928, 0.751488, 0.402398, 1.041992, 0.093209, 0.623516, 0.532925, 1.042992, 0.093714, 0.621958, 0.534484]\n",
    "    \n",
    "    # append the rescaled vector to x \n",
    "    for i in range(0, 36):\n",
    "        min = min_[i]\n",
    "        max = max_[i] \n",
    "        x.append(-1 + (2.0/(max - min) * (features[i] - min)))\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading names of bad quality & good quality images\n",
    "os.chdir(r'E:\\Downloads\\iqa_assignment')\n",
    "bq = os.listdir(r'E:\\Downloads\\iqa_assignment\\bad_quality')\n",
    "gq = os.listdir(r'E:\\Downloads\\iqa_assignment\\good_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\Downloads\\\\iqa_assignment'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nidhi\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:72: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    }
   ],
   "source": [
    "#reading good quality images & creating features for them in a df \n",
    "\n",
    "#dataframe with good quality images\n",
    "df_gq = pd.DataFrame(columns=np.arange(0,37))\n",
    "\n",
    "#dataframe with bad quality images\n",
    "df_bq = pd.DataFrame(columns=np.arange(0,37))\n",
    "\n",
    "def creating_df(df_name, list_name, path):\n",
    "    count=0\n",
    "    for i in list_name:\n",
    "        df_name.loc[count]=test_measure_BRISQUE(path+\"//\"+i) \n",
    "        count=count+1\n",
    "        \n",
    "    return(df_name)\n",
    "        \n",
    "df_gq= creating_df(df_gq, gq, path='good_quality')\n",
    "df_bq= creating_df(df_bq, bq, path='bad_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining target\n",
    "df_bq['target']=0\n",
    "df_gq['target']=1\n",
    "df = pd.concat([df_bq, df_gq], axis=0)\n",
    "df.drop(0, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'], test_size=0.3, stratify=df['target'], random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling minority classes\n",
    "oversample = SMOTE(sampling_strategy=1)\n",
    "X_train, Y = oversample.fit_resample(x_train, y_train)\n",
    "\n",
    "i=0\n",
    "setused=X_train\n",
    "targ=Y\n",
    "\n",
    "scores=[]\n",
    "accuracy_train=[]\n",
    "accuracy_test=[]\n",
    "\n",
    "splits=10\n",
    "X_test = np.array(x_test)\n",
    "cnf_matrix=[]\n",
    "oof_preds = np.zeros((len(X_test)))\n",
    "kfold, scores = StratifiedKFold(n_splits=splits,random_state=True), list()\n",
    "for train2, test2 in kfold.split(setused,targ):\n",
    "    x_train, x_test = setused[train2], setused[test2]\n",
    "    y_train, y_test = targ[train2], targ[test2]\n",
    "    eval_set = [(x_test,y_test)]\n",
    "    #x_train, y_train = oversample.fit_resample(x_train, y_train) \n",
    "    model = xgboost.XGBClassifier(random_state=27)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    \n",
    "    preds = model.predict_proba(x_test)[:, 1]\n",
    "    \n",
    "    preds_class = model.predict(x_test)\n",
    "    preds_class_train = model.predict(x_train)\n",
    "\n",
    "    accuracy_train.append( round(accuracy_score(y_train, preds_class_train), 2)*100)\n",
    "    accuracy_test.append( round(accuracy_score(y_test, preds_class), 2)*100)    \n",
    "    \n",
    "    oof_preds += model.predict_proba(X_test)[:, 1]\n",
    "oof_preds = oof_preds/splits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
